---
title: LSTM åŸç†åŠå…¶ PyTorch å®ç°
date: 2024-12-13 13:00:36
tags: 
    - PyTorch
    - æ·±åº¦å­¦ä¹ 
categories:
    - æ·±åº¦å­¦ä¹ 
    - RNN æ—ç®—æ³•
description: |
    ğŸ“– ä½¿ç”¨ PyTorch å®ç° LSTM
---
> PyTorch å…¶å®å†…ç½®äº† LSTM æ¨¡å‹ï¼Œç›´æ¥è°ƒç”¨å³å¯ï¼Œä¸éœ€è¦è´¹åŠ²å»æ‰‹æ“äº†
>
> ï¼ˆæŸä¸ªäººå¤ç°åˆ°ä¸€åŠæ‰ååº”è¿‡æ¥ ğŸ˜­ï¼‰
>
> âœ¨é€šä¿—æ˜“æ‡‚çš„ LSTM åŸç†è®²è§£ï¼ˆåŠ›æ¨ï¼‰ï¼š
> https://www.youtube.com/watch?v=YCzL96nL7j0&t=1s
>
> ï¼ˆ å‘æ˜ LSTM çš„äººçœŸ ** æ˜¯ä¸ªå¤©æ‰ï¼ï¼‰

## 1. â“ ä»€ä¹ˆæ˜¯ LSTM
é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼ŒLong-Short-Term Memoryï¼‰æ˜¯ä¼ ç»Ÿ RNN ç½‘ç»œçš„ Plus ç‰ˆæœ¬ã€‚
### 1.1 å‘æ˜èƒŒæ™¯
ä¼ ç»Ÿçš„ RNN ç½‘ç»œåœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œå½“é‡åˆ°é•¿åºåˆ—æ•°æ®æ—¶ï¼Œå¾ˆå®¹æ˜“å‡ºç° **æ¢¯åº¦çˆ†ç‚¸** ä¸ **æ¢¯åº¦æ¶ˆå¤±** çš„æƒ…å†µï¼Œå¯¼è‡´è®­ç»ƒæ•ˆæœä¸å¤ªå¥½ã€‚

ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼ŒLSTM åœ¨ä¼ ç»Ÿ RNN çš„åŸºç¡€ä¸Šï¼ŒåŠ å…¥äº† **é—¨æ§æœºåˆ¶ï¼ˆGateï¼‰** æ¥æ§åˆ¶ä¿¡æ¯æµåŠ¨ï¼Œä»è€Œè®°ä½é•¿æœŸä¾èµ–ä¿¡æ¯ã€‚

### 1.2 åŸç†è¯¦è§£
å…ˆçœ‹è§†é¢‘ï¼šhttps://www.youtube.com/watch?v=YCzL96nL7j0&t=1s

LSTM ç”±å¤šä¸ª **LSTM å•å…ƒï¼ˆCellï¼‰** ç»„æˆï¼Œæ¯ä¸ªå•å…ƒåŒ…å«ä»¥ä¸‹ä¸‰ä¸ªé—¨å’Œä¸€ä¸ªå•å…ƒçŠ¶æ€ï¼š  

#### **é—å¿˜é—¨ï¼ˆForget Gateï¼‰**
- **åŠŸèƒ½ï¼š** å†³å®šå“ªäº›ä¿¡æ¯éœ€è¦ **é—å¿˜**ã€‚
- **å…¬å¼ï¼š**  
$$ f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f) $$
- **è§£é‡Šï¼š**
  - è¾“å…¥ï¼šå‰ä¸€ä¸ªéšè—çŠ¶æ€ $h_{t-1}$ å’Œå½“å‰è¾“å…¥ $x_t$ã€‚
  - è¾“å‡ºï¼šèŒƒå›´åœ¨ $[0, 1]$ï¼Œå…¶ä¸­ 0 è¡¨ç¤ºå®Œå…¨é—å¿˜ï¼Œ1 è¡¨ç¤ºå®Œå…¨ä¿ç•™ã€‚  

#### **è¾“å…¥é—¨ï¼ˆInput Gateï¼‰**
- **åŠŸèƒ½ï¼š** å†³å®šå“ªäº›æ–°ä¿¡æ¯éœ€è¦ **å­˜å‚¨**ã€‚
- **å…¬å¼ï¼š**
  - å€™é€‰ä¿¡æ¯ç”Ÿæˆï¼š  
    $$
    \tilde{C}_t = \tanh(W_C \cdot [h_{t-1}, x_t] + b_C)
    $$
  - è¾“å…¥é—¨æ¿€æ´»ï¼š  
    $$
    i_t = \sigma(W_i \cdot [h_{t-1}, x_t] + b_i)
    $$
  - æ›´æ–°å•å…ƒçŠ¶æ€ï¼š  
    $$
    C_t = f_t \cdot C_{t-1} + i_t \cdot \tilde{C}_t
    $$
- **è§£é‡Šï¼š**
  - å€™é€‰ä¿¡æ¯ $\tilde{C}_t$ï¼šå½“å‰æ—¶é—´æ­¥çš„æ–°ä¿¡æ¯ã€‚
  - è¾“å…¥é—¨ $i_t$ï¼šæ§åˆ¶å€™é€‰ä¿¡æ¯çš„å­˜å‚¨ç¨‹åº¦ã€‚  

#### **è¾“å‡ºé—¨ï¼ˆOutput Gateï¼‰**
- **åŠŸèƒ½ï¼š** å†³å®šå•å…ƒçŠ¶æ€ä¸­çš„ä¿¡æ¯ **å…¬å¼€è¾“å‡º**ã€‚
- **å…¬å¼ï¼š**
  - è¾“å‡ºé—¨æ¿€æ´»ï¼š  
    $$
    o_t = \sigma(W_o \cdot [h_{t-1}, x_t] + b_o)
    $$
  - æœ€ç»ˆéšè—çŠ¶æ€ï¼š  
    $$
    h_t = o_t \cdot \tanh(C_t)
    $$
- **è§£é‡Šï¼š**
  - è¾“å‡ºé—¨å†³å®šå½“å‰æ—¶é—´æ­¥çš„éšè—çŠ¶æ€ $h_t$ï¼Œè¯¥çŠ¶æ€å°†ä½œä¸ºä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥ã€‚

#### **å•å…ƒçŠ¶æ€ï¼ˆCell Stateï¼‰**
- **åŠŸèƒ½ï¼š**  
  - ä½œä¸ºä¿¡æ¯çš„â€œé•¿æœŸè®°å¿†â€è·¯å¾„ï¼Œåœ¨æ•´ä¸ªæ—¶é—´åºåˆ—ä¸­æµåŠ¨ã€‚
  - çº¿æ€§ä¼ é€’ï¼Œå‡ ä¹ä¸å—æ¿€æ´»å‡½æ•°çš„å½±å“ï¼Œç¡®ä¿é•¿æ—¶é—´çš„ä¿¡æ¯ä¿ç•™ã€‚

### 1.3 LSTM æ•°æ®æµæ€»ç»“ï¼š
1. æ¥æ”¶è¾“å…¥ $x_t$ å’Œä¸Šä¸€ä¸ªéšè—çŠ¶æ€ $h_{t-1}$ã€‚  
2. **é—å¿˜é—¨** ç¡®å®šéœ€è¦é—å¿˜çš„ä¿¡æ¯ã€‚  
3. **è¾“å…¥é—¨** ç¡®å®šå­˜å‚¨çš„æ–°ä¿¡æ¯ã€‚  
4. æ›´æ–°å•å…ƒçŠ¶æ€ $C_t$ã€‚  
5. **è¾“å‡ºé—¨** ç¡®å®šå½“å‰æ—¶é—´æ­¥çš„è¾“å‡ºéšè—çŠ¶æ€ $h_t$ã€‚  

### 1.4 LSTM çš„ä¼˜åŠ¿ï¼š
- **é•¿æœŸä¾èµ–è®°å¿†ï¼š** èƒ½å¤Ÿæœ‰æ•ˆè®°ä½é•¿æœŸä¿¡æ¯ï¼Œè§£å†³äº†ä¼ ç»Ÿ RNN çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚
- **é€‚ç”¨åœºæ™¯ï¼š** å¹¿æ³›ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ã€æ—¶é—´åºåˆ—é¢„æµ‹ã€è¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸã€‚  
- **çµæ´»æ€§é«˜ï¼š** æ”¯æŒå¤šå±‚å †å ï¼Œèƒ½å¤Ÿå­¦ä¹ é«˜åº¦å¤æ‚çš„æ•°æ®æ¨¡å¼ã€‚  

---

## 2. PyTorch å®ç° LSTM
### 2.1 å¯¼å…¥å¿…è¦çš„åº“
```Python
import torch
import torch.nn as nn
import torch.optim as optim
```

### 2.2 å®šä¹‰ LSTM æ¨¡å‹

```Python
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers=1):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        out = self.fc(lstm_out[:, -1, :])  # åªå–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        return out
```

PyTorch æä¾›çš„ `nn.LSTM` å«æœ‰å››ä¸ªå‚æ•°ï¼š`input_size`ã€`hidden_size`ã€`num_layers`ã€`batch_first`ã€‚

å…¶ä¸­ï¼Œ`batch_first` ç”¨äºæŒ‡å®šè¾“å…¥å¼ é‡çš„ç»´åº¦é¡ºåºï¼Œæ§åˆ¶è¾“å…¥å’Œè¾“å‡ºå¼ é‡çš„å½¢çŠ¶è§£é‡Šæ–¹å¼ï¼š

- é»˜è®¤å€¼ï¼š`batch_first=True`
  - è¾“å…¥å¼ é‡å½¢çŠ¶ï¼š`(seq_len, batch_size, input_size)`
  - è¾“å‡ºå¼ é‡å½¢çŠ¶ï¼š`(seq_len, batch_size, hidden_size)`
- è®¾ç½®ä¸º `batch_first=True`ï¼š
  - è¾“å…¥å¼ é‡å½¢çŠ¶ï¼š`(batch_size, seq_len, input_size)`
  - è¾“å‡ºå¼ é‡å½¢çŠ¶ï¼š`(batch_size, seq_len, hidden_size)`

è¿™é‡Œä¸ºä»€ä¹ˆæˆ‘ä»¬è¦ç”¨ `batch_first=True` å‘¢ï¼Ÿ
- è®¾ç½® `batch_first=True` æ›´ç¬¦åˆå¤§å¤šæ•°æ·±åº¦å­¦ä¹ åº“çš„å¸¸ç”¨å¼ é‡å½¢å¼ï¼Œä½¿ä»£ç æ›´ç›´è§‚ã€‚


### 2.3 åˆå§‹åŒ–æ¨¡å‹å’Œè¶…å‚æ•°

```Python
input_size = 10    # è¾“å…¥ç‰¹å¾æ•°
hidden_size = 50   # éšè—å±‚å¤§å°
output_size = 1    # è¾“å‡ºç‰¹å¾æ•°
num_layers = 2     # LSTM å±‚æ•°

model = LSTMModel(input_size, hidden_size, output_size, num_layers)
criterion = nn.MSELoss()  # æŸå¤±å‡½æ•°
optimizer = optim.Adam(model.parameters(), lr=0.001)
```

### 2.4 åˆ›å»ºæ•°æ®ç¤ºä¾‹

```Python
# ç”Ÿæˆéšæœºè¾“å…¥å’Œæ ‡ç­¾
x_train = torch.randn(100, 5, input_size)  # (æ‰¹æ¬¡å¤§å°, æ—¶é—´æ­¥, è¾“å…¥å¤§å°)
y_train = torch.randn(100, output_size)
```

### 2.5 è®­ç»ƒæ¨¡å‹

```Python
num_epochs = 100

for epoch in range(num_epochs):
    model.train()
    outputs = model(x_train)
    loss = criterion(outputs, y_train)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if (epoch+1) % 10 == 0:
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')
```

### 2.6 è¯„ä¼°æ¨¡å‹

```Python
model.eval()
with torch.no_grad():
    test_input = torch.randn(1, 5, input_size)
    prediction = model(test_input)
    print(f'Prediction: {prediction}')
```
