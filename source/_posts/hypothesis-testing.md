---
title: 常用假设检验方法及 Python 实现
date: 2025-05-22 18:08:49
tags:
    - 统计学
    - 机器学习
categories: 
    - 数学
description: |
    📚 常用假设检验方法及 Python 实现
---
## 1. 什么是假设检验？
> 参考文章：https://blog.csdn.net/weixin_37861936/article/details/103928494

### 1.1 概念
**假设检验（Hypothesis testing）**，又称统计假设检验，是用来判断样本与样本、样本与总体的差异是由抽样误差引起还是本质差别造成的统计推断方法。显著性检验是假设检验中最常用的一种方法，也是一种最基本的统计推断形式，其基本原理是先对总体的特征做出某种假设，然后通过抽样研究的统计推理，对此假设应该被拒绝还是接受做出推断。常用的假设检验方法包括 Z 检验、t 检验、卡方检验、F 检验等。

### 1.2 步骤
假设检验的步骤如下：
- 确定要进行检验的假设，包括原假设 $H_0$ 和备择假设 $H_1$
- 选择检验的方法，计算统计量
- 根据显著性水平，确定用于做出决策的拒绝域
- 查看样本结果是否位于拒绝域内
- 做出决策

### 1.3 其他概念
假设检验的几个重要概念
- $H_0$（原假设）：即要对其进行检验的断言，除非有足够的证据拒绝，否则将接受原假设
- $H_1$（备择假设）：在拒绝原假设之后将要接受的断言，通常与原假设对立
- $\alpha$（显著性水平）：指当**原假设为正确**时人们却**把它拒绝**了的概率或风险。它是公认的小概率时间的概率值，必须在每一次统计检验之前确定，通常取 $\alpha=0.05$ 或 $\alpha=0.01$
- 单尾检验：拒绝域落在可能的数据集的一侧
- 双尾检验：拒绝域落在可能的数据集的两侧

### 1.4 双尾检验与单尾检验
使用单位检验还是双尾检验，取决于备择假设的形式：

| 拒绝域的位置 | 原假设 $H_0$ | 备择假设 $H_1$ |
|---|---|---|
| 双尾 | $H_0:\theta = \theta _0$ | $H_1:\theta \ne \theta _0$ |
| 左单尾 | $H_0:\theta \ge \theta _0$ | $H_1:\theta < \theta _0$ |
| 右单尾 | $H_0:\theta \le \theta _0$ | $H_1:\theta > \theta _0$ |

### 1.5 假设检验的基本思想
小概率事件在一次实验中是几乎不可能发生的，**假若在一次实验中事件事实上发生了，那只能认为事件不是来自我们假设的总体，也就是认为我们对总体所作的假设不正确**。

### 1.6 假设检验中的两类错误
- **弃真错误**：原假设事实上正确，可是检验统计量的观察值却落入拒绝域，因此否定了本来正确的假设，$p(弃真)=\alpha$
- **取伪错误**：原假设事实上不正确，可是检验统计量的观察值却落入了接受域，因为没有否定本来不正确的原假设。

### 1.7 P 值
当原假设为真时所取得的样本观察结果中极端结果出现的概率。

如果 P 值很小，说明原假设情况的发生概率很小，而如果出现了，根据**小概率原理**，我们就有理由拒绝原假设，P 值越小，我们拒绝原假设的理由越充分。

| P值 | 碰巧的概率 | 对原假设 $H_0$ | 统计学意义 |
|---|---|---|---|
| $p>0.05$ |碰巧出现的可能性大于 5% | 不能否定原假设 $H_0$| 两组差别无显著意义 |
| $p<0.05$ | 碰巧出现的可能性小于 5% | 可以否定原假设 $H_0$| 两组差别有显著意义 |
| $p<0.01$ | 碰巧出现的可能性小于 1% | 可以否定原假设 $H_0$ | 两组差别有非常显著意义 |

## 2. 卡方检验
### 2.1 概念
卡方检验的根本思想在于**比较理论频数和实际频数的吻合程度或拟合优度问题**。卡方检验分为卡方拟合度检验和卡方独立性检验。

> **卡方分布** $\chi^2$：若 $n$ 个相互独立的随机变量 $\zeta_1$，$\zeta_2$，...，$\zeta_n$ 均服从标准正态分布（也称独立同分布于标准正态分布），则这 $n$ 个服从标准正态分布的随机变量的平方和构成一新的随机变量，其分布规律称为卡方分布

### 2.2 核心思想
卡方检验是以卡方分布为基础的一种常用假设检验方法。

原假设 $H_0$ 是：观察频数与期望频数没有差别。

$$\chi^2 = \Sigma \frac{(A-E)^2}{E}=\Sigma^k_{i=1} \frac{(A_i-E_i)^2}{E_i}$$

$A$：某个类别的观察频数
$E$：基于原假设 $H_0$ 计算出的期望频数
$A-E$：残差

> **求和之前除以期望频数的原因**：观察频数与期望频数的差距是相对较大还是较小，取决于期望频数的大小。例如期望频数为1000，观察频数为1040和期望频数为10，观察频数为50，差值均为40，但是显然后者的期望与实际的差距显然大于前者的期望和实际的差距。

$\chi^2$ 是观察频数与期望频数之间距离的一种度量指标，也是假设成立与否的度量指标。如果 $\chi^2$ 值小，就倾向于不拒绝 $H_0$；如果 $\chi^2$ 值大，就倾向于拒绝 $H_0$。至于 $\chi^2$ 在每个具体研究中究竟要大到什么程度才能拒绝 $H_0$，则要借助于卡方分布求出所对应的 P 值来确定。

### 2.3 卡方分布的用途
- 检验某个连续变量的分布是否与理论分布一致
- 检验某个分类变量各类的出现概率是否等于指定概率
- 检验某两个分类变量是否相互独立。如吸烟是否与呼吸道疾病有关
- 检验控制某种或某几种分类因素的作用以后，另两个分类变量是否相互独立

> 卡方拟合优度检验的自由度为 $df=k-1$，其中 $k$ 代表分类变量数
> 卡方独立性检验的自由度为 $df=(R-1)(C-1)$，$R$ 代表行数，$C$ 代表列数。

### 2.4 卡方检验实例与 Python 实现

（⚠️ Coldrain 最近迷上了 `Node.js`，故本文暂停一天）